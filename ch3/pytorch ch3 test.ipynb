{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef82c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, ReLU\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fbefdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3442,  1.3424, -0.0624, -0.2083, -0.6045]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer = Linear(in_features=10,out_features=5,bias=True) # 輸入特徵數為 10，輸出特徵數為 5，並啟用偏差（bias）\n",
    "inp = Variable(torch.randn(1,10))\n",
    "myLayer(inp) # 執行線性轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d923820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0388, -0.2929, -0.0886,  0.2930,  0.2227, -0.1821, -0.2815, -0.0637,\n",
       "         -0.2247,  0.2648],\n",
       "        [ 0.2461, -0.0985, -0.2300,  0.1556, -0.0641, -0.1608,  0.0818,  0.2959,\n",
       "         -0.2484,  0.1862],\n",
       "        [ 0.1704, -0.1136, -0.1565, -0.2362,  0.1928, -0.1212, -0.0436, -0.2342,\n",
       "         -0.2410,  0.0882],\n",
       "        [-0.0122,  0.1800, -0.0034, -0.0599,  0.2724,  0.1632, -0.1307, -0.0951,\n",
       "          0.2645, -0.0450],\n",
       "        [ 0.0702, -0.0760, -0.0509,  0.2062,  0.2856,  0.3123, -0.3155,  0.1065,\n",
       "         -0.1144, -0.1153]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eacf1436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2805,  0.0407, -0.2590, -0.1784, -0.2585], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d91238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1616, 0.2674]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer1 = Linear(10,5) # 輸入特徵數為 10，輸出特徵數為 5 \n",
    "myLayer2 = Linear(5,2) # 要進入下一層需要符合上一層輸出特徵數\n",
    "myLayer2(myLayer1(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2261d228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = Variable(torch.Tensor([[1,2,-1,-1]])) \n",
    "myRelu = ReLU()\n",
    "myRelu(sample_data) #  使用ReLU函數，負值將取為0，正值則不變"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29eaee00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "sample_data = Variable(torch.Tensor([[1,2,-1,-1]])) \n",
    "f = F.relu(sample_data) # Much simpler.\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f118d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFirstNetwork(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(MyFirstNetwork,self).__init__() \n",
    "        self.layer1 = nn.Linear(input_size,hidden_size) # 透過這兩個線性層，模型可以學習從輸入到輸出的映射。在每一層之間，使用 ReLU 激活函數（torch.relu）來引入非線性。\n",
    "        self.layer2 = nn.Linear(hidden_size,output_size)\n",
    "    def __forward__(self,input): \n",
    "        out = self.layer1(input) # 執行了線性轉換操作，將輸入資料映射到隱藏層（hidden layer）的空間。\n",
    "        out = nn.ReLU(out)\n",
    "        out = self.layer2(out) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1650d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss() # 創建一個均方誤差的損失函數，並將其存儲在 loss 變數中。\n",
    "input = Variable(torch.randn(3, 5), requires_grad=True)\n",
    "target = Variable(torch.randn(3, 5))\n",
    "output = loss(input, target) # 計算模型輸出 (input) 與目標值 (target) 之間的均方誤差損失。\n",
    "output.backward() # 執行反向傳播，計算損失對於輸入變數 input 的梯度。這將使得 input 中的 requires_grad 為 True 的元素具有相對於損失的梯度值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b65c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(true_label, prediction): # 計算交叉熵損失\n",
    "    if true_label == 1:\n",
    "        return -log(prediction)\n",
    "    else:\n",
    "        return -log(1 - prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a19f9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = Variable(torch.randn(3, 5), requires_grad=True) \n",
    "target = Variable(torch.LongTensor(3).random_(5)) \n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e8040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
